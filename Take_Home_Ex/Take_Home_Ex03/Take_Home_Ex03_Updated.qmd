---
title: "Take_Home_Ex03_Updated"
author: "Wong Kelly"
date-modified: "`r Sys.Date()`"

format: html
execute: 
  echo: true
  eval: true
  warning: false
editor: visual
---

# 1. Overview

Housing is an essential component of household wealth worldwide. Buying a housing has always been a major investment for most people. The price of housing is affected by many factors. Some of them are global in nature such as the general economy of a country or inflation rate. Others can be more specific to the properties themselves. These factors can be further divided to structural and locational factors. Structural factors are variables related to the property themselves such as the size, fitting, and tenure of the property. Locational factors are variables related to the neighbourhood of the properties such as proximity to childcare centre, public transport service and shopping centre.

![](images/2201175.webp)

Conventional, housing resale prices predictive models were built by using [**Ordinary Least Square (OLS)**](https://en.wikipedia.org/wiki/Ordinary_least_squares) method. However, this method failed to take into consideration that spatial autocorrelation and spatial heterogeneity exist in geographic data sets such as housing transactions. With the existence of spatial autocorrelation, the OLS estimation of predictive housing resale pricing models could lead to biased, inconsistent, or inefficient results (Anselin 1998). In view of this limitation, **Geographical Weighted Models** were introduced for calibrating predictive model for housing resale prices.

## 1.1 The Task

In this take-home exercise, we are tasked to ***predict HDB resale prices at the sub-market level (i.e.Â HDB 3-room, HDB 4-room and HDB 5-room) for the month of January and February 2023 in Singapore.*** The predictive models must be built by using by using conventional OLS method and GWR methods. ***We are also required to compare the performance of the conventional OLS method versus the geographical weighted methods.***

# 2. Data Acquisition Source

For the purpose of this take-home exercise, [`HDB Resale Flat Prices`](https://data.gov.sg/dataset/resale-flat-prices) provided by Data.gov.sg should be used as the core data set. The study should focus on either three-room, four-room or five-room flat and transaction period should be from 1st January 2021 to 31st December 2022. The test data should be January and February 2023 resale prices.

In addition, we will also include other locational factors such as proximity of HDB to eldercare services, and shopping malls etc for considerations.

***Data Summary Table***

| Type                           | Name                                  | Format   | Source                                                      |
|------------------|------------------|------------------|-------------------|
| Aspatial                       | HDB resale flat prices                | .csv     | data.gov.sg                                                 |
| Geospatial                     | Master plan 2014 subzone web boundary | .shp     | data.gov.sg                                                 |
| Geospatial (Locational factor) | Elder care services                   | .shp     | data.gov.sg                                                 |
| Geospatial (Locational factor) | Hawker centres                        | .geojson | data.gov.sg                                                 |
| Geospatial (Locational factor) | MRT stations                          | .shp     |                                                             |
| Geospatial (Locational factor) | Supermarkets                          | .geojson | data.gov.sg                                                 |
| Geospatial (Locational factor) | Student care services                 | .geojson | data.gov.sg                                                 |
| Geospatial (Locational factor) | Shopping Malls                        | .csv     | <https://github.com/ValaryLim/Mall-Coordinates-Web-Scraper> |
| Geospatial (Locational factor) | Bus Stops                             | .shp     | data.gov.sg                                                 |
| Geospatial (Locational factor) | Dengue clusters                       | .geojson | data.gov.sg                                                 |
| Geospatial (Locational factor) | Parks                                 | .kml     | data.gov.sg                                                 |
| Geospatial (Locational factor) | Kindergartens                         | .shp     | data.gov.sg                                                 |

# 3. Getting Started

## 3.1 Installing and Loading the R packages

```{r}
pacman::p_load(olsrr, sf, spdep, sfdep, GWmodel, tmap, tidyverse, gtsummary, SpatialML,rsample,Metrics, jsonlite,httr,rvest,sp)
```

The R packages installed that we will be using for take-home assignment 3 are:

-   **sf:** used for importing, managing, and processing geospatial data

-   **tmap:** used for creating thematic maps, such as choropleth and bubble maps

-   **tidyverse:** a collection of packages for data science tasks

-   **sfdep:** An interface for 'spdep' to integrate with 'sf' objects and the 'tidyverse'

-   **plotly:** used for creating interactive and dynamic visualisations in R

-   **olsrr**: designed for use with ordinary least squares (OLS) regression

-   **GWmodel**: (TO CONTINUEEEE)

# 4. Data Wrangling: Geospatial Data & Aspatial Data

## **4.1 Importing Aspatial Data**

```{r}
resale <- read_csv("data/aspatial/resale-flat-prices-based-on-registration-date-from-jan-2017-onwards.csv")
```

From the results above, we can tell that:

-   The dataset contains 11 columns with 148,000 rows in total.

-   The timeframe of the dataset is from 2017 January to 2023 February up to date (from the review of dataset).

-   The columns that are present in the data are: month, town, flat_type, block, street_name, storey_range, floor_area_sqm, flat_model, lease_commence_date, remaining_lease, resale_price (from the review of dataset).

In this take-home assignment, **I selected HDB 4-room flat resale prices to analyse** during the **transaction period from 1st January 2021 to 31st December 2022**. Therefore, we will need to filter and only extract data during this period of time frame.

### 4.1.1 Filter Resale Data

As mentioned in the previous section of 4.1, we are only interested in (1) HDB 4-room flat resale prices during the period of (2) 1st January 2021 to 31st December 2022. Let's filter them!

```{r}
rs_subset <-  filter(resale,flat_type == "4 ROOM") %>% 
              filter(month >= "2021-01" & month <= "2023-03")
```

From the results above, we can tell that:

-   We have successfully filtered our data based on earlier chosen HDB model flat and transaction period!

-   From January 2021 to December 2022, there are **23,657 transactions** for 4-room flat in Singapore.

Additionally, we will need to extract another data set for our testing model which is between the period of January 2023 to February 2023.

```{r}
rs_subset_test <-  filter(resale,flat_type == "4 ROOM") %>% 
              filter(month >= "2023-01" & month <= "2023-02")
```

From the results above, we can tell that:

-   We have successfully filtered our test data as well!

-   From January 2023 to February 2023, there are **1848 transactions** for 4-room flat in Singapore.

### 4.1.2 Transform Resale Data

After we have extracted the rows of transactions we are interested in, we will then proceed to use *mutate* function of dplyr package to create new variables (columns) in a data frame by applying some transformations to the existing columns.

What we will need to do is:

-   **address**: concatenation of the block and street_name columns using paste() function of base R package.

-   **remaining_lease_yr & remaining_lease_mnth**: Split the year and months part of the remaining_lease respectively using str_sub() function of stringr package then converting the character to integer using as.integer() function of base R package.

-   After performing mutate function, we will store the new data in **rs_transform.**

```{r}
rs_transform <- rs_subset %>%
  mutate(rs_subset, address = paste(block,street_name)) %>%
  mutate(rs_subset, remaining_lease_yr = as.integer(str_sub(remaining_lease, 0, 2))) %>%
  mutate(rs_subset, remaining_lease_mnth = as.integer(str_sub(remaining_lease, 9, 11)))
```

After we have successfully added the three variables (address, remaining_lease_yr, and remaining_lease_mnth) into a new data named rs_transform, we will see some NA values in the remaining_lease_mnth column. Therefore, we will need to replace those with a value of 0 using *is.na()* function of base R package.

```{r}
rs_transform$remaining_lease_mnth[is.na(rs_transform$remaining_lease_mnth)] <- 0
rs_transform
```

Now, as we scroll to the remaining_lease_mnth column, we noticed all initial "NA" values have been replaced by 0!

Next, we do not want to segregate the remaining lease in years and months columns. Instead, we could convert the remaining_lease_yr to months unit and create a new column call total_remaining_lease for easier analysis later using *mutate* function of dplyr package which contains the summation of the remaining_lease_yr and remaining_lease_mnth using *rowSum()* function of base R package. Here is how we do it!

```{r}
# Multiply remaining_lease_yr column in months unit
rs_transform$remaining_lease_yr <- rs_transform$remaining_lease_yr * 12

# Create a new column: total_remaining_lease to contain the summation of yr and mnth
rs_transform <- rs_transform %>% 
  mutate(rs_transform, total_remaining_lease = rowSums(rs_transform[, c("remaining_lease_yr", "remaining_lease_mnth")])) %>%
  select(month, town, address, block, street_name, flat_type, storey_range, floor_area_sqm, flat_model, 
         lease_commence_date, total_remaining_lease, resale_price)

# Display head of data
head(rs_transform)
```

Upon inspection of the rs_transform, we now only left with one column: total_remaining_lease that contains all the remaining lease in months!

### 4.1.3 Retrieve Postal Codes and Coordinates of Addresses

In this section, we will focus on retrieving the relevant data like postal codes and coordinates of the address which is required to get the proximity to locational factors in the later parts.

Here are the steps to add its longitude and latitude features with OneMapSG API!

***Step 1: Create a list storing unique addresses***

```{r}
add_list <- sort(unique(rs_transform$address))
```

***Step 2: Create function to retrieve coordinates from OneMapSG API***

```{r}
get_coords <- function(add_list){
  
  # Create a data frame to store all retrieved coordinates
  postal_coords <- data.frame()
    
  for (i in add_list){

    r <- GET('https://developers.onemap.sg/commonapi/search?',
           query=list(searchVal=i,
                     returnGeom='Y',
                     getAddrDetails='Y'))
    
    # Send a GET request to OneMap API with address as searchVal,
    # returnGeom as 'Y' to retrieve the coordinates, and getAddrDetails as 'Y' to retrieve the postal code

    
    data <- fromJSON(rawToChar(r$content))
    found <- data$found
    res <- data$results
    
    # Extract the 'found' and 'results' fields from the API reponses
    
    # Create a new data frame for each address
    new_row <- data.frame()
    
    # If single result, append 
    if (found == 1){
      postal <- res$POSTAL 
      lat <- res$LATITUDE
      lng <- res$LONGITUDE
      new_row <- data.frame(address= i, postal = postal, latitude = lat, longitude = lng)
    }
    
    # If multiple results, drop NIL and append top 1
    else if (found > 1){
      # Remove those with NIL as postal
      res_sub <- res[res$POSTAL != "NIL", ]
      
      # Set as NA first if no Postal
      if (nrow(res_sub) == 0) {
          new_row <- data.frame(address= i, postal = NA, latitude = NA, longitude = NA)
      }
      
      else{
        top1 <- head(res_sub, n = 1)
        postal <- top1$POSTAL 
        lat <- top1$LATITUDE
        lng <- top1$LONGITUDE
        new_row <- data.frame(address= i, postal = postal, latitude = lat, longitude = lng)
      }
    }

    else {
      new_row <- data.frame(address= i, postal = NA, latitude = NA, longitude = NA)
    }
    
    # Add the row
    postal_coords <- rbind(postal_coords, new_row)
  }
  return(postal_coords)
}
```

***Step 3: Call get_coords function to retrieve resale coordinates***

After retrieving the coords for the first time, it will be commented out to reduce the rendering time as the time taken to run and process the code chunk below is about 5 to 6 minutes each time.

```{r}

#coords <- get_coords(add_list)
```

The code chunk below will be used to save the coords data file in csv format for future use.

```{r}

#write_rds(coords,"data/rds/coords.csv")
#coords
```

We will then read the coords.csv data and use it for the following parts.

```{r}
coords <- read_rds("data/rds/coords.csv")
coords
```

### 4.1.4 Combine Resale and Coordinates Data

After we have done retrieving the location coordinates of all the resale HDBs, we need to now combine our resale data (rs_transform) earlier with the coordinates data (coords) using *left_join()* function.

```{r}
rs_coords <- left_join(rs_transform, coords, by = c('address' = 'address'))
```

Great! We have successfully joined the two data sets and now let's write the file to our rds folder!

```{r}
rs_coords_rds <- write_rds(rs_coords, "data/rds/rs_coords.rds")
```

Now, let's read rs_coords RDS file:

```{r}
rs_coords <- read_rds("data/rds/rs_coords.rds")
```

### 4.1.5 Assign and Transform CRS and Check

The coordinate columns (latitude, longitude) are currently in decimal degrees, the projected CRS will be WGS84. We will need to convert it into a spatial data frame with projected coordinates of 3414.

```{r}
rs_coords_sf <- st_as_sf(rs_coords,
                    coords = c("longitude", 
                               "latitude"),
                    crs=4326) %>%
  st_transform(crs = 3414)
```

```{r}
st_crs(rs_coords_sf)
```

#### 4.1.5.1 Check for Invalid Geometries

```{r}
length(which(st_is_valid(rs_coords_sf) == FALSE))
```

We have no invalid geometries! Now, let's plot hdb resale points

```{r}
tmap_mode("view")
tm_shape(rs_coords_sf)+
  tm_dots(col="red", size = 0.02)
tmap_mode("plot")
```

# 5. Import Geospatial Locational Factors Data (WITH geographic coordinates)

## 5.1 Import ALL Locational Factors Data Sets

In this section, we will read and process all the locational factors data as they are important in determining the HDB resale prices as we believe good location with good amenities will have a higher resale price and vice versa.

Firstly, we will need to read and check CRS of all locational factors!

```{r}
#geojson files
hawker_sf <- st_read("data/geospatial_locational_GC/hawker-centres/hawker-centres-geojson.geojson")
supermarket_sf <- st_read("data/geospatial_locational_GC/supermarkets/supermarkets-geojson.geojson")
student_sf <- st_read("data/geospatial_locational_GC/student-care-services/student-care-services-geojson.geojson")
dengue_sf <- st_read("data/geospatial_locational_GC/dengue-clusters/dengue-clusters-geojson.geojson")
train_sf <- st_read("data/geospatial_locational_GC/mrtstation/lta-mrt-station-exit-geojson.geojson")


#shp files
elder_sf <- st_read(dsn = "data/geospatial_locational_GC/eldercare-services", layer="ELDERCARE")
bus_sf <- st_read(dsn = "data/geospatial_locational_GC/BusStopLocation", layer="BusStop")
kindergarten_sf <- st_read(dsn = "data/geospatial_locational_GC/kindergartens", layer="KINDERGARTENS")
park_sf <- st_read(dsn = "data/geospatial_locational_GC/nationalparks", layer="NATIONALPARKS")

```

From the results above, we can see that the datasets are all in different CRS:

-   The datasets with WGS84 are:

    -   hawker_sf, supermarket_sf, student_sf, dengue_sf, park_sf,train_sf

    -   As the EPSG code are in 4326 which is the appropriate EPSG code for WGS84, we will only need to transform the CRS later on

-   The datasets with SVY21 are:

    -   elder_sf, train_sf, bus_sf, kindergarten_sf

    -   For all of these datasets with SVY21 ???

-   The dataset read in csv????

## 5.2 Transform all Data to CRS EPSG 3414

::: panel-tabset
Transform Data to EPSG 3414

```{r}
elder_sf <- st_set_crs(elder_sf, 3414)
train_sf <- st_set_crs(train_sf, 3414)
bus_sf <- st_set_crs(bus_sf, 3414)
kindergarten_sf <- st_set_crs(kindergarten_sf, 3414)
park_sf <- st_set_crs(park_sf, 3414)

hawker_sf <- hawker_sf %>%
  st_transform(crs = 3414)
supermarket_sf <- supermarket_sf %>%
  st_transform(crs = 3414)
student_sf <- student_sf %>%
  st_transform(crs = 3414)
dengue_sf <- dengue_sf %>%
  st_transform(crs = 3414)
```

st_crs

```{r}
st_crs(elder_sf)
st_crs(train_sf)
st_crs(bus_sf)
st_crs(kindergarten_sf)
st_crs(hawker_sf)
st_crs(supermarket_sf)
st_crs(student_sf)
st_crs(dengue_sf)
st_crs(park_sf)
```
:::

From the above results, we can see that the EPSG code of all the data has now been assigned correctly and they are all EPSG 3414.

### 5.2.1 Check for Invalid Geometries

Since all the datasets above have been converted to the appropraite EPSG, we should also check for any invalid geometries to avoid any issues when calculating proximity or plot the map.

```{r}
length(which(st_is_valid(elder_sf) == FALSE))
length(which(st_is_valid(train_sf) == FALSE))
length(which(st_is_valid(bus_sf) == FALSE))
length(which(st_is_valid(kindergarten_sf) == FALSE))
length(which(st_is_valid(hawker_sf) == FALSE))
length(which(st_is_valid(supermarket_sf) == FALSE))
length(which(st_is_valid(student_sf) == FALSE))
length(which(st_is_valid(dengue_sf) == FALSE))
length(which(st_is_valid(park_sf) == FALSE))
```

From the results above, we can see that there are no invalid geometries for all the locational factors! That means we can move on to calculate proximity.

## 5.3 Calculate Proximity

### 5.3.1 Create get_prox function to calculate proximity

```{r}
get_prox <- function(df1, df2, varname){
  
  # creates a matrix of distances
  dist_matrix <- st_distance(df1, df2)           
  
  # find the nearest location_factor and create new data frame
  near <- df1 %>% 
    mutate(PROX = apply(dist_matrix, 1, function(x) min(x)) / 1000) 
  
  # rename column name according to input parameter
  names(near)[names(near) == 'PROX'] <- varname

  # Return df
  return(near)
}
```

### 5.3.2 Call get_prox function

```{r}
rs_coords_sf <- get_prox(rs_coords_sf, elder_sf, "PROX_ELDERLYCARE") 
rs_coords_sf <- get_prox(rs_coords_sf, train_sf, "PROX_TRAIN") 
rs_coords_sf <- get_prox(rs_coords_sf, bus_sf, "PROX_BUS") 
rs_coords_sf <- get_prox(rs_coords_sf, kindergarten_sf, "PROX_KINDERGARTEN") 
rs_coords_sf <- get_prox(rs_coords_sf, hawker_sf, "PROX_HAWKER")
rs_coords_sf <- get_prox(rs_coords_sf, supermarket_sf, "PROX_SUPERMARKET")
rs_coords_sf <- get_prox(rs_coords_sf, student_sf, "PROX_STUDENT")
rs_coords_sf <- get_prox(rs_coords_sf, dengue_sf, "PROX_DENGUE")
rs_coords_sf <- get_prox(rs_coords_sf, park_sf, "PROX_PARK")
```

### 5.3.3 Create get_within function to calculate factors that are within the declared distance

```{r}
get_within <- function(df1, df2, threshold_dist, varname){
  
  # creates a matrix of distances
  dist_matrix <- st_distance(df1, df2)   
  
  # count the number of location_factors within threshold_dist and create new data frame
  wdist <- df1 %>% 
    mutate(WITHIN_DT = apply(dist_matrix, 1, function(x) sum(x <= threshold_dist)))
  
  # rename column name according to input parameter
  names(wdist)[names(wdist) == 'WITHIN_DT'] <- varname

  # Return df
  return(wdist)
}

```

**5.3.4 Call get_within function**

-   ***Kindergartens that are within the distance of 350m***

```{r}
rs_coords_sf <- get_within(rs_coords_sf, kindergarten_sf, 350, "WITHIN_350M_KINDERGARTEN")
```

-   ***Childcare services that are within the distance of 350m***

```{r}
rs_coords_sf <- get_within(rs_coords_sf, student_sf, 350, "WITHIN_350M_CHILDCARE")
```

-   ***Bus stop that are within the distance of 350m***

```{r}
rs_coords_sf <- get_within(rs_coords_sf, bus_sf, 350, "WITHIN_350M_BUS")
```

# 6. Import Geospatial Locational Factors Data (WITHOUT geographic coordinates)

In this section, we will retrieve those locational factors that do not have any geographic coordinates.

## 6.1 CBD

Since we are unable to find a list of Singapore Central Business District (CBD) data list and its corresponding geographic coordinates, we will need to do a search of the latitude and longitude of Downtown Core also known as CBD.

Latitude: 1.287953

Longitude: 103.851784

Then, we can create a dataframe consisting of the latitude and longitude coordinates of the CBD area then transform it to EPSG 3414 (SVY21) format.

***Step 1: Store CBD coordinates in database***

```{r}
name <- c('CBD Area')
latitude= c(1.287953)
longitude= c(103.851784)
cbd_coords <- data.frame(name, latitude, longitude)
```

***Step 2: Assign and transform CRS***

```{r}
cbd_coords_sf <- st_as_sf(cbd_coords,
                    coords = c("longitude", 
                               "latitude"),
                    crs=4326) %>%
  st_transform(crs = 3414)
```

```{r}
st_crs(cbd_coords_sf)
```

From the results above, we can see that:

-   Coordinates for CBD area in EPSG 3414 (SVY21) format is c(30055.05, 30040.83)

-   We can now run out get_prox function to calculate the proximity of HDB and CBD area!

***Step 3: Call get_prox function***

```{r}
rs_coords_sf <- get_prox(rs_coords_sf, cbd_coords_sf, "PROX_CBD") 
```

## 6.2 Shopping Malls

Similar to CBD, there are no exisiting datasets that we can download for shopping malls in Singapore with corresponding geographic coordinates. Therefore, we would need to extract

1.  Extract shopping malls from wikipedia

```{r}
url <- "https://en.wikipedia.org/wiki/List_of_shopping_malls_in_Singapore"
malls_list <- list()

for (i in 2:7){
  malls <- read_html(url) %>%
    html_nodes(xpath = paste('//*[@id="mw-content-text"]/div[1]/div[',as.character(i),']/ul/li',sep="") ) %>%
    html_text()
  malls_list <- append(malls_list, malls)
}
```

```{r}
malls_list
```

2.  call get_coords function

```{r}
malls_list_coords <- get_coords(malls_list) %>% 
  rename("mall_name" = "address")
```

3.  Remove invalid shopping mall name

```{r}
malls_list_coords <- subset(malls_list_coords, mall_name!= "Yew Tee Shopping Centre")

```

4.  correct invalid mall names that can be found

```{r}
invalid_malls<- subset(malls_list_coords, is.na(malls_list_coords$postal))
invalid_malls_list <- unique(invalid_malls$mall_name)
corrected_malls <- c("Clarke Quay", "City Gate", "Raffles Holland V", "Knightsbridge", "Mustafa Centre", "GR.ID", "Shaw House",
                     "The Poiz Centre", "Velocity @ Novena Square", "Singapore Post Centre", "PLQ Mall", "KINEX", "The Grandstand")

for (i in 1:length(invalid_malls_list)) {
  malls_list_coords <- malls_list_coords %>% 
    mutate(mall_name = ifelse(as.character(mall_name) == invalid_malls_list[i], corrected_malls[i], as.character(mall_name)))
}
```

5.  Create a list storing unique mall names

```{r}
malls_list <- sort(unique(malls_list_coords$mall_name))
```

6.  Call get_coords to retrieve coordinates of shopping malls again

```{r}
malls_coords <- get_coords(malls_list)
```

7.  Inspect results

```{r}
malls_coords[(is.na(malls_coords$postal) | is.na(malls_coords$latitude) | is.na(malls_coords$longitude)), ]

```

```{r}
malls_sf <- st_as_sf(malls_coords,
                    coords = c("longitude", 
                               "latitude"),
                    crs=4326) %>%
  st_transform(crs = 3414)
```

```{r}
rs_coords_sf <- get_prox(rs_coords_sf, malls_sf, "PROX_MALL") 
```

## 6.4 Primary Schools

```{r}
pri_sch <- read_csv("data/geospatial_locational_nonGC/school-directory-and-information/general-information-of-schools.csv")
```

```{r}
pri_sch <- pri_sch %>%
  filter(mainlevel_code == "PRIMARY") %>%
  select(school_name, address, postal_code, mainlevel_code)
```

```{r}
glimpse(pri_sch)
```

```{r}
prisch_list <- sort(unique(pri_sch$postal_code))
```

```{r}
prisch_coords <- get_coords(prisch_list)
```

```{r}
prisch_coords[(is.na(prisch_coords$postal) | is.na(prisch_coords$latitude) | is.na(prisch_coords$longitude)), ]

```

```{r}
prisch_coords = prisch_coords[c("postal","latitude", "longitude")]
pri_sch <- left_join(pri_sch, prisch_coords, by = c('postal_code' = 'postal'))
```

```{r}
head(pri_sch)
```

```{r}
prisch_sf <- st_as_sf(pri_sch,
                    coords = c("longitude", 
                               "latitude"),
                    crs=4326) %>%
  st_transform(crs = 3414)
```

```{r}
st_crs(prisch_sf)
```

```{r}
rs_coords_sf <- get_within(rs_coords_sf, prisch_sf, 1000, "WITHIN_1KM_PRISCH")

```

```{r}
head(rs_coords_sf)
```

## 6.5 Good Primary Schools (Top 10)

```{r}
url <- "https://www.salary.sg/2021/best-primary-schools-2021-by-popularity/"

good_pri <- data.frame()

schools <- read_html(url) %>%
  html_nodes(xpath = paste('//*[@id="post-3068"]/div[3]/div/div/ol/li') ) %>%
  html_text() 

for (i in (schools)){
  sch_name <- toupper(gsub(" â .*","",i))
  sch_name <- gsub("\\(PRIMARY SECTION)","",sch_name)
  sch_name <- trimws(sch_name)
  new_row <- data.frame(pri_sch_name=sch_name)
  # Add the row
  good_pri <- rbind(good_pri, new_row)
}

top_good_pri <- head(good_pri, 10)
```

```{r}
head(top_good_pri)
```

```{r}
top_good_pri$pri_sch_name[!top_good_pri$pri_sch_name %in% prisch_sf$school_name]
```

```{r}
good_pri_list <- unique(top_good_pri$pri_sch_name)
```

```{r}
goodprisch_coords <- get_coords(good_pri_list)
```

```{r}
goodprisch_coords[(is.na(goodprisch_coords$postal) | is.na(goodprisch_coords$latitude) | is.na(goodprisch_coords$longitude)), ]
```

```{r}
top_good_pri$pri_sch_name[top_good_pri$pri_sch_name == "CHIJ ST. NICHOLAS GIRLSâ SCHOOL"] <- "CHIJ SAINT NICHOLAS GIRLS' SCHOOL"
top_good_pri$pri_sch_name[top_good_pri$pri_sch_name == "ST. HILDAâS PRIMARY SCHOOL"] <- "SAINT HILDA'S PRIMARY SCHOOL"
```

```{r}
good_pri_list <- unique(top_good_pri$pri_sch_name)
```

```{r}
goodprisch_coords <- get_coords(good_pri_list)
```

```{r}
goodprisch_coords[(is.na(goodprisch_coords$postal) | is.na(goodprisch_coords$latitude) | is.na(goodprisch_coords$longitude)), ]

```

```{r}
goodpri_sf <- st_as_sf(goodprisch_coords,
                    coords = c("longitude", 
                               "latitude"),
                    crs=4326) %>%
  st_transform(crs = 3414)
```

```{r}
rs_coords_sf <- get_prox(rs_coords_sf, goodpri_sf, "PROX_GOOD_PRISCH")

```

```{r}
rs_factors_rds <- write_rds(rs_coords_sf, "data/rds/rs_factors.rds")
```

```{r}
rs_factors_rds <- read_rds("data/rds/rs_factors.rds")
rs_factors_rds
```

7.  Import Data for Analysis
    1.  Geospatial Data

```{r}
mpsz_sf <- st_read(dsn = "data/geospatial", layer="MP14_SUBZONE_WEB_PL")

```

```{r}
st_crs(mpsz_sf)
```

```{r}
mpsz_sf <- st_transform(mpsz_sf, 3414)
```

```{r}
st_crs(mpsz_sf)
```

```{r}
length(which(st_is_valid(mpsz_sf) == FALSE))
```

```{r}
mpsz_sf <- st_make_valid(mpsz_sf)
length(which(st_is_valid(mpsz_sf) == FALSE))
```

```{r}

rs_sf <- read_rds("data/rds/rs_factors.rds")

```

```{r}

storeys <- sort(unique(rs_sf$storey_range))

```

```{r}

storey_order <- 1:length(storeys)
storey_range_order <- data.frame(storeys, storey_order)

```

```{r}
head(storey_range_order)

```

```{r}

rs_sf <- left_join(rs_sf, storey_range_order, by=c("storey_range" = "storeys"))

```

```{r}

glimpse(rs_sf)

```

```{r}
write_rds(rs_sf,"data/rds/rs_sf.rds")
```

```{r}
rs_sf <- read_rds("data/rds/rs_sf.rds")
```

```{r}

train_data <- rs_sf %>% filter(month >= "2022-10" & month <= "2022-12")
test_data <- rs_sf %>% filter(month >= "2023-01" & month <= "2023-02")
```

```{r}
#| eval: false
write_rds(train_data, "data/rds/train_data.rds")
write_rds(test_data, "data/rds/test_data.rds")
```

```{r}
train_data <- read_rds("data/rds/train_data.rds")
test_data <- read_rds("data/rds/test_data.rds")

```

Build a non-spatial multiple linear regression

```{r}
price_mlr <- lm(resale_price ~ floor_area_sqm +
                  storey_order + total_remaining_lease + PROX_GOOD_PRISCH +
                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +
                  PROX_TRAIN + PROX_PARK + PROX_MALL + PROX_BUS + PROX_KINDERGARTEN +
                  PROX_SUPERMARKET + PROX_STUDENT + PROX_DENGUE + WITHIN_350M_KINDERGARTEN +
                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +
                  WITHIN_1KM_PRISCH,
                data=train_data)
summary(price_mlr)
```

```{r}

write_rds(price_mlr, "data/rds/price_mlr.rds" ) 

```

gwr prediction method

```{r}
train_data_sp <- as_Spatial(train_data)
train_data_sp

```

```{r}
#| eval: false
bw_adaptive <- bw.gwr(resale_price ~ floor_area_sqm +
                  storey_order + total_remaining_lease + PROX_GOOD_PRISCH +
                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +
                  PROX_TRAIN + PROX_PARK + PROX_MALL + PROX_BUS + PROX_KINDERGARTEN +
                  PROX_SUPERMARKET + PROX_STUDENT + PROX_DENGUE + WITHIN_350M_KINDERGARTEN +
                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +
                  WITHIN_1KM_PRISCH,
                  data=train_data_sp,
                  approach="CV",
                  kernel="gaussian",
                  adaptive=TRUE,
                  longlat=FALSE)
```

```{r}
#| eval: false
write_rds(bw_adaptive, "data/rds/bw_adaptive.rds")

```

```{r}
bw_adaptive <- read_rds("data/rds/bw_adaptive.rds")
bw_adaptive
```

```{r}
#| eval: false
gwr_adaptive <- gwr.basic(formula = resale_price ~ floor_area_sqm +
                  storey_order + total_remaining_lease + PROX_GOOD_PRISCH +
                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +
                  PROX_TRAIN + PROX_PARK + PROX_MALL + PROX_BUS + PROX_KINDERGARTEN +
                  PROX_SUPERMARKET + PROX_STUDENT + PROX_DENGUE + WITHIN_350M_KINDERGARTEN +
                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +
                  WITHIN_1KM_PRISCH,
                  data=train_data_sp,
                          bw=bw_adaptive, 
                          kernel = 'gaussian', 
                          adaptive=TRUE,
                          longlat = FALSE)
```

```{r}
#| eval: false
write_rds(gwr_adaptive, "data/rds/gwr_adaptive.rds")

```

```{r}
gwr_adaptive <- read_rds("data/rds/gwr_adaptive.rds")
gwr_adaptive
```

Preparing coordinates data

```{r}
coords <- st_coordinates(rs_sf)
coords_train <- st_coordinates(train_data)
coords_test <- st_coordinates(test_data)
```

```{r}
coords_train <- write_rds(coords_train, "data/rds/coords_train.rds" )
coords_test <- write_rds(coords_test, "data/rds/coords_test.rds" )
```

Droping geometry field

```{r}
train_data <- train_data %>% 
  st_drop_geometry()

```

Calibrating Random Forest Model

```{r}
set.seed(1234)
rf <- ranger(formula = resale_price ~ floor_area_sqm +
                  storey_order + total_remaining_lease + PROX_GOOD_PRISCH +
                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +
                  PROX_TRAIN + PROX_PARK + PROX_MALL + PROX_BUS + PROX_KINDERGARTEN +
                  PROX_SUPERMARKET + PROX_STUDENT + PROX_DENGUE + WITHIN_350M_KINDERGARTEN +
                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +
                  WITHIN_1KM_PRISCH,
             data=train_data)

```

```{r}
print(rf)
```

Calibrating Geographical Random Forest Model

(Calibrating using training data)

```{r}
#| eval: false
bwRF_adaptive <- grf.bw(formula = resale_price ~ floor_area_sqm +
                  storey_order + total_remaining_lease + PROX_GOOD_PRISCH +
                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +
                  PROX_TRAIN + PROX_PARK + PROX_MALL + PROX_BUS + PROX_KINDERGARTEN +
                  PROX_SUPERMARKET + PROX_STUDENT + PROX_DENGUE + WITHIN_350M_KINDERGARTEN +
                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +
                  WITHIN_1KM_PRISCH, train_data,
                  kernel = "adaptive",
                  coords=coords_train,
                  step = 10,
                  trees=30)

```

```{r}
#| eval: false
set.seed(1234)
gwRF_adaptive <- grf(formula = resale_price ~ floor_area_sqm +
                  storey_order + total_remaining_lease + PROX_GOOD_PRISCH +
                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +
                  PROX_TRAIN + PROX_PARK + PROX_MALL + PROX_BUS + PROX_KINDERGARTEN +
                  PROX_SUPERMARKET + PROX_STUDENT + PROX_DENGUE + WITHIN_350M_KINDERGARTEN +
                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +
                  WITHIN_1KM_PRISCH,
                     train_data, 
                     ntree = 30,
                     bw=296,
                     kernel="adaptive",
                     coords=coords_train)

```

```{r}
#| eval: false
write_rds(gwRF_adaptive, "data/rds/gwRF_adaptive.rds")

```

```{r}

gwRF_adaptive <- read_rds("data/rds/gwRF_adaptive.rds")

```

Predicting by using test data

(preparing the test data)

```{r}
test_data <- cbind(test_data, coords_test) %>%
  st_drop_geometry()
```

```{r}
any(is.na(test_data))
test_data[rowSums(is.na(test_data))!=0,]

```

```{r}
#| eval: false
gwRF_pred <- predict.grf(gwRF_adaptive, 
                           test_data, 
                           x.var.name="X",
                           y.var.name="Y", 
                           local.w=1,
                           global.w=0)

```

```{r}
#| eval: false
GRF_pred <- write_rds(gwRF_pred, "data/rds/GRF_pred.rds")
```

```{r}
GRF_pred <- read_rds("data/rds/GRF_pred.rds")
GRF_pred_df <- as.data.frame(GRF_pred)

```

```{r}

test_data_p <- cbind(test_data, GRF_pred_df)
```

```{r}
write_rds(test_data_p, "data/rds/test_data_p.rds")
```

```{r}
rmse(test_data_p$resale_price, 
     test_data_p$GRF_pred)
```

```{r}
ggplot(data = test_data_p,
       aes(x = GRF_pred,
           y = resale_price)) +
  geom_point()

```
A better predictive model should have the scatter point close to the diagonal line. The scatter plot can be also used to detect if any outliers in the model.
