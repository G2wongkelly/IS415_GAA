---
title: "Take-Home Exercise 2: Spatio-temporal Analysis of COVID-19 Vaccination Trends at the Sub-district level, DKI Jakarta"
author: "Wong Kelly"
date-modified: "`r Sys.Date()`"
format: html
execute: 
  echo: true
  eval: true
  warning: false
editor: visual
---

# 1. Overview

Since late December 2019, an outbreak of a novel coronavirus disease (COVID-19; previously known as 2019-nCoV) was reported in Wuhan, China, which had subsequently affected 210 countries worldwide. In general, COVID-19 is an acute resolved disease but it can also be deadly, with a 2% case fatality rate.

The COVID-19 vaccination in Indonesia is an ongoing mass immunisation in response to the COVID-19 pandemic in Indonesia. On 13 January 2021, the program commenced when President Joko Widodo was vaccinated at the presidential palace. In terms of total doses given, Indonesia ranks third in Asia and fifth in the world.

![](images/549b2ae32b24e82a48c812462eac72dc.jpg)

According to wikipedia, as of 5 February 2023 at 18:00 WIB (UTC+7), 204,266,655 people had received the first dose of the vaccine and 175,131,893 people had been fully vaccinated; 69,597,474 of them had been inoculated with the booster or the third dose, while 1,585,164 had received the fourth dose. Jakarta has the highest percentage of population fully vaccinated with 103.46%, followed by Bali and Special Region of Yogyakarta with 85.45% and 83.02% respectively.

## 1.1 Problem Statement & Objectives

*Despite its compactness, the cumulative vaccination rate are not evenly distributed within DKI Jarkata. **The question is where are the sub-districts with relatively higher number of vaccination rate and how they changed over time (July 2021 to June 2022).***

Exploratory Spatial Data Analysis (ESDA) hold tremendous potential to address complex problems facing society. In this study, students are tasked to apply appropriate Local Indicators of Spatial Association (LISA) and Emerging Hot Spot Analysis (EHSA) to undercover the spatio-temporal trends of COVID-19 vaccination in DKI Jakarta.

# **2. Data Acquisition Source**

***Apstial data***

For the purpose of this assignment, data from [Riwayat File Vaksinasi DKI Jakarta](https://riwayat-file-vaksinasi-dki-jakarta-jakartagis.hub.arcgis.com/) will be used. Daily vaccination data are provides. You are only required to download either the first day of the month or last day of the month of the study period. I opted to download the first day of the month data during the period from July 2021 to June 2022.

***Geospatial data***

For the purpose of this study, DKI Jakarta administration boundary 2019 will be used. The data set can be downloaded at Indonesia Geospatial portal, specifically at [this page](https://www.indonesia-geospasial.com/2020/04/download-shapefile-shp-batas-desa.html).

***Data summary table***

| Type       | Name                                                      | Format    | Description                                                                             |
|------------|------------------|------------|------------------------------|
| Geospatial | Shapefile (SHP) Batas Desa Provinsi DKI Jakarta           | shapefile | Sub-districts in DKI Jarkarta                                                           |
| Aspatial   | Data Vaksinasi Berbasis Kelurahan dan Kecamatan (Monthly) | .csv      | Sub-district level data of COVID-19 cases in DKI Jarkata between July 2021 to June 2022 |

# 3. Getting started

## 3.1 Installing and Loading the R packages

```{r}
#explain the packages - what are their purposes
pacman::p_load(sf, tmap,tidyverse, sfdep, plotly, zoo)
```

The R packages installed that we will be using for analysis are:

-   **sf:** used for importing, managing, and processing geospatial data

-   **tidyverse:** a collection of packages for data science tasks

-   **tmap:** used for creating thematic maps, such as choropleth and bubble maps

-   **sfdep:**

-   **plotly:** used for creating interactive and dynamic visualisations in R

-   **zoo:** A popular package for working with time series data

# 4. Data Wrangling: Geospatial Data & Aspatial Data

## **4.1 Importing Geospatial Data**

```{r}
bd_jakarta <- st_read(dsn="data/geospatial",
                     layer="BATAS_DESA_DESEMBER_2019_DUKCAPIL_DKI_JAKARTA")
```

From the output message, we learn that:

-   Geometry type is multipolygon

-   269 features and 161 fields

-   Assigned CRS is WGS 84 (geographic coordinate system)

-   Dimension is XY

### 4.1.1 Geospatial Data Pre-Processing (Cleaning)

Similar to our take-home assignment 1, before we can visualise our datasets and do the necessary analysis, we have to do data cleaning which is an important step in any data science task including geospatial data science. Things to check:

-   Invalid geometries

-   Missing value

***(1) Invalid geometries***

```{r}
length(which(st_is_valid(bd_jakarta) == FALSE))
```

***(2) Missing value***

```{r}
bd_jakarta[rowSums(is.na(bd_jakarta))!=0,]
```

From the output generated above, we can tell that there are two particulars rows with missing values for KAB_KOTA (City), KECAMATAN (District), and DESA_KELUR (Village), as well as other fields such as OBJECT_ID 25645 and 25646. Therefore, we will need to remove them from the data.

```{r}
#removes rows that have an NA value in DESA_KELUR
bd_jakarta <- na.omit(bd_jakarta,c("DESA_KELUR"))
```

```{r}
#re-run to check if there is anymore NA value
bd_jakarta[rowSums(is.na(bd_jakarta))!=0,]
```

Great! The data now is cleaned with no missing values! :)

### 4.1.2 Verifying & Data Transformation

```{r}
#retrieves the coordinate system of bd_jakarta
st_crs(bd_jakarta)
```

According to the output message above, we learn that the current assigned coordinate system is WGS 84, the "World Geodetic System 1984". However, in the context of this data set, it is an Indonesian-specific geospatial data set. Therefore, we should be using the national CRS of Indonesia, **DGN95, the "Datum Geodesi Nasional 1995", ESPG code 23845**. Let's rectify that:

```{r}
#transform WGS84 to DGN95, ESPG code 23845
bd_jakarta <- st_transform(bd_jakarta, 23845)
st_crs(bd_jakarta)
```

From the above output message, we can tell that the original coordinate system (WGS 84) has been successfully transformed to Indonesia coordinate system (DGN 95).

Now, let's plot the geometry to quickly visualise the data.

### 4.1.3 Verifying & Removing Outer Islands

```{r}
plot(st_geometry(bd_jakarta))
```

As we can see, bd_jakarta includes both the mainland and the outer islands. However, in the context of this assignment, we are not interested in the outer islands. Therefore, we can eliminate them out.

We will first output the unique values of PROVINSE (province) and KAB_KOTA (city) fields to inspect the distribution of clusters.

```{r}
# outputs unique values of province and city fields
unique(bd_jakarta$"PROVINSI")
unique(bd_jakarta$"KAB_KOTA")
```

Noticed from the output message above, the province are the same for all rows. However, as for KAB_KOTA, cities of Jakarta, realised that most of the cities have a JAKARTA prefix except for KEPULAUAN SERIBU (translated to 'Thousand Islands') refers to the outer islands. Just to check, we will plot the geometry of the geospatial data set once again with cluster of colours.

```{r}
tm_shape(bd_jakarta) +
  tm_polygons("KAB_KOTA")
```

Now we can clearly identify the outer islands and they are the "orange" mini clusters spreading outside the main islands. We will then remove them from our data set:

```{r}
bd_jakarta <- filter(bd_jakarta , KAB_KOTA != "KEPULAUAN SERIBU")
```

Let us check if they are removed by plotting the map again!

```{r}
tm_shape(bd_jakarta) +
  tm_polygons("KAB_KOTA")
```

Yes! we have successfully excluded the outer islands from the map and left us with only the mainland which are the cities that start with the "JAKARTA" prefix.

### 4.1.4 Retaining relevant columns & Renaming them with translation (English)

There are too many columns in the date file bd_jakarta and we will need to only retain the fields that are relevant to our analysis which are the first 9 fields in the bd_jakarta data frame.

```{r}
# Retain only the first 9 fields of bd_jakarta
bd_jakarta <- bd_jakarta[, 0:9]
```

Next, we need to also rename the retained columns to English language for ease of understanding for analysis later.

```{r}
bd_jakarta <- bd_jakarta %>% 
  dplyr::rename(
    Object_ID=OBJECT_ID,
    Province=PROVINSI, 
    City=KAB_KOTA, 
    District=KECAMATAN, 
    Village_Code=KODE_DESA, 
    Village=DESA, 
    Sub_District=DESA_KELUR,
    Code=KODE, 
    Total_Population=JUMLAH_PEN
    )
```

We are done with our Geospatial data processing and now let's move on the Aspatial data!

## **4.2 Importing Aspatial Data**

In our "data/aspatial" folder, we have multiple sub-district level data of COVID-19 cases in DKI Jarkata between July 2021 to June 2022. Therefore, we would want to find a more efficient way to import all of them instead of one by one.

In the code chunk below, we first use **`list.files()`** function to get a list of all CSV files in the directory **`data/aspatial/`**. Then, we use the **`lapply()`** function to read each file in the list using **`read_csv()`** and store the resulting data frames in a list named **`data_list`**. Finally, we use **`do.call()`** function to combine all the data frames in the list into one large data frame named **`result_file`**.

```{r}
csv_files <- list.files(path = "data/aspatial/", pattern = "*.csv")

# read all CSV files into a list of data frames
data_list <- lapply(csv_files, function(file) {
  read_csv(paste("data/aspatial/", file, sep = ""))
})
```

### **4.2.1 Data Pre-Processing (Cleaning)**

```{r}
#Take a quick glance of all the data sets in the list of imported aspatial files
data_list
```

A total of 12 aspatial data files imported and among these data files, there are three variety of column number (34,27, and 21 variables).

![](images/image-197263346.png){width="203" height="50"}

![](images/image-641691436.png){width="201" height="40"}

![](images/image-1914119294.png){width="196"}

Therefore, we will use the following code line to see the variety in columns for all the data sets.

```{r}

#view column names in each data file
lapply(data_list, colnames)
```

![](images/image-932730584.png){width="559"}

I took out 3 samples out of the 12 data files to show the difference in number of variables. I realised the differences were due to column names ie. \_\_\_ which means elderly when translated into English. The reason could be due to the progressive \_\_ for demographics by the government.

However, the primary interest in this study is to analyse COVID-19 vaccination trends at the sub-district level, DKI Jakarta. Therefore, the breakdown of different demographics vaccination progress are less of our concern and we should eliminate them from the data sets.

Our columns of interest (those that are relevant to our analysis and we will keep) are as follows (as highlighted in blue in the above screenshot as well) -\> they are common in all data files therefore we can extract them:

-   Kode Kelurahan (Village Code)
-   Wilayah Kota (City Area)
-   Kecamatan (District)
-   Kelurahan (Sub-District)
-   Sasaran (Target)
-   Belum Vaksin (Not Yet Vaccinated)
-   Total Vaksin Diberikan (Total Vaccine Given)

Now that we know our requirements, we can process the data step-by-step:

***Step 1: Retain only the 7 relevant columns for all 12 data sets imported earlier***

In this code, the **`map()`** function iterates through each data frame in the list **`my_data`** and applies the **`select()`** function to select the stated column names. The resulting list of data frames is stored in the variable **`my_data_same_columns`**.

```{r}
my_data_same_columns <- map(data_list, ~select(.x, "KODE KELURAHAN", "WILAYAH KOTA", "KECAMATAN","SASARAN","KELURAHAN","BELUM VAKSIN","TOTAL VAKSIN\nDIBERIKAN"))

my_data_same_columns
```

Now, all the data files have 7 declared same columns.

***Step 2: Rename Columns with translation (English headers)***

```{r}
# Define a named vector of new column names
new_names <- c("Village_Code" = "KODE KELURAHAN", "City_Area" = "WILAYAH KOTA", "District" = "KECAMATAN", "Sub_District"="KELURAHAN", "Target" = "SASARAN", "Unvaccinated" = "BELUM VAKSIN", "Vaccinated" = "TOTAL VAKSIN\nDIBERIKAN")

# Use map to rename columns in each data frame in the list
renamed_list <- map(my_data_same_columns, ~rename(.x, !!!new_names))

# View the renamed data frames in the list
glimpse(renamed_list)
```

***Step 3: Create the date column to identify each file of different months in the list***

```{r}
date_value_1 <- "April 01, 2022"
renamed_list_1 <- renamed_list[[1]]
renamed_list_1$date <- as.Date(date_value_1, format = "%B %d, %Y")

renamed_list_1

date_value_2 <- "August 01, 2021"
renamed_list_2 <- renamed_list[[2]]
renamed_list_2$date <- as.Date(date_value_2, format = "%B %d, %Y")

renamed_list_2

date_value_3 <- "December 01, 2021"
renamed_list_3 <- renamed_list[[3]]
renamed_list_3$date <- as.Date(date_value_3, format = "%B %d, %Y")

renamed_list_3

date_value_4 <- "February 01, 2022"
renamed_list_4 <- renamed_list[[4]]
renamed_list_4$date <- as.Date(date_value_4, format = "%B %d, %Y")

renamed_list_4

date_value_5 <- "January 01, 2022"
renamed_list_5 <- renamed_list[[5]]
renamed_list_5$date <- as.Date(date_value_5, format = "%B %d, %Y")

renamed_list_5

date_value_6 <- "July 01, 2021"
renamed_list_6 <- renamed_list[[6]]
renamed_list_6$date <- as.Date(date_value_6, format = "%B %d, %Y")

renamed_list_6

date_value_7 <- "June 01, 2022"
renamed_list_7 <- renamed_list[[7]]
renamed_list_7$date <- as.Date(date_value_7, format = "%B %d, %Y")

renamed_list_7

date_value_8 <- "March 01, 2022"
renamed_list_8 <- renamed_list[[8]]
renamed_list_8$date <- as.Date(date_value_8, format = "%B %d, %Y")

renamed_list_8

date_value_9 <- "May 01, 2022"
renamed_list_9 <- renamed_list[[9]]
renamed_list_9$date <- as.Date(date_value_9, format = "%B %d, %Y")

renamed_list_9

date_value_10 <- "November 01, 2021"
renamed_list_10 <- renamed_list[[10]]
renamed_list_10$date <- as.Date(date_value_10, format = "%B %d, %Y")

renamed_list_10

date_value_11 <- "October 01, 2021"
renamed_list_11 <- renamed_list[[11]]
renamed_list_11$date <- as.Date(date_value_11, format = "%B %d, %Y")

renamed_list_11

date_value_12 <- "September 01, 2021"
renamed_list_12 <- renamed_list[[12]]
renamed_list_12$date <- as.Date(date_value_12, format = "%B %d, %Y")

renamed_list_12
```

***Step 4: Changing data type + Joining all the Aspatial CSV files together***

Note that I am unable to join renamed_list_9 data set because of the data type as shown below -\> quantitative data should be categorize as number instead of char. Therefore, there is a conflict when joining with the other data files.

To resolve the issue, we will need to change the data type of village code, target, unvaccinated, and vaccinated data fields to numeric type before joining.

![](images/image-645052536.png)

```{r}
#Convert the respective variables to numeric data type 
#check with prof how to change the other variables data type as well!

renamed_list_11 <- renamed_list_11 %>% 
  filter(!str_detect(Village_Code, "\\D")) %>% 
  mutate(Village_Code = as.numeric(Village_Code), Target = as.numeric(Target), Unvaccinated = as.numeric(Unvaccinated), Vaccinated = as.numeric(Vaccinated))

renamed_list_11
```

![](images/image-523161187.png){width="612"}

Now that we have converted the data type in renamed_list_11, we can proceed to join all the Aspatial cleaned data files!

```{r}
combined_df <- bind_rows(renamed_list_1,renamed_list_2,renamed_list_3,renamed_list_4,renamed_list_5,renamed_list_6,renamed_list_7, renamed_list_8,renamed_list_9,renamed_list_10,renamed_list_11, renamed_list_12)
```

![](images/image-470434038.png){width="341" height="20"}

The combined data file has a total of 3259 observations (rows) and 8 variables (columns).

```{r}
# remove total in sub-dsitrict for the time being

TOTAL_removed_combined_df <- combined_df[combined_df$`Sub_District` != "TOTAL", ]
```

# 5. Joining Geospatial & Aspatial data frames

```{r}
colnames(bd_jakarta)
```

```{r}
colnames(TOTAL_removed_combined_df)
```

It seems that

-   **Village_code -\> Village_Code,**

-   **City -\> City_Area, and**

-   **District -\> District**

-   **Sub_District -\> Sub_District**

should match up! Let's try doing that first:

```{r}

bd_jakarta <- bd_jakarta %>% mutate(Village_Code = as.numeric(Village_Code))

combined_Jakarta_district_level <- left_join(bd_jakarta, TOTAL_removed_combined_df,by=c(
                                "Village_Code"="Village_Code",
                                "City"="City_Area",
                                "District" = "District",
                                "Sub_District" = "Sub_District"))
```

Now, let's visualise our current combined_jakarta in terms of the total count of target and unvaccinated:

```{r}
prelim_target = tm_shape(combined_Jakarta_district_level)+
  tm_fill("Target") +
  tm_borders(alpha = 0.2) +
  tm_layout(main.title="Preliminary Target Count")

prelim_Unvaccinated = tm_shape(combined_Jakarta_district_level)+
  tm_fill("Unvaccinated") +
  tm_borders(alpha = 0.2) +
  tm_layout(main.title="Preliminary Unvaccinated Count")

tmap_arrange(prelim_target, prelim_Unvaccinated)
```

As seen from the output maps above, there are still some 'missing' values even though we have removed all NA records from both sets of data. The reason might be due to inconsistency in naming for example, some district might be \_\_\_\_\_\_\_. However, this is just my assumption! Let us know check it!

## 5.1 Identifying Mismatched Records\*\*



# 6. Calculations

Before we prepare the monthly vaccination rate maps, we need to first **compute the monthly vaccinate rate from July 2021 to June 2022 at sub-district** **level** (also known as kelurahan in Bahasa Indonesia). The formula to calculate this should be:

$$
Monthly Vaccination Rate = ((Target-Total unvaccinated count) / Target)*100)
$$

```{r}

vaccine_rate <- TOTAL_removed_combined_df %>%
  inner_join(bd_jakarta, by=c("Sub_District" = "Sub_District")) %>%
  group_by(Sub_District, date) %>%
  dplyr::summarise(`MonthlyVaccinationRate` = (((Target-Unvaccinated)/Target)*100)) %>%
  ungroup() %>% pivot_wider(names_from = date,
              values_from = MonthlyVaccinationRate)
```

```{r}
# vaccine_rate is currently a datafram, in order to map them, we should convert these dataframes into sf objects
combined_Jakarta_district_level <- st_as_sf(combined_Jakarta_district_level)

#need to join our previous dataframes with the geospatial data to ensure that the geometry column is present
vaccine_rate <- vaccine_rate%>% left_join(bd_jakarta, by=c("Sub_District"="Sub_District"))
vaccine_rate <- st_as_sf(vaccine_rate)
#show that the dataframe has transformed (screenshot)
```

## 6.1 Mapping: Monthly Cumulative Vaccinate Rate (for 12 months)

Prepare the monthly vaccination rate maps by using appropriate tmap functions (multiple maps for 12 months like megan work)

```{r}
tmap_mode("plot")
tm_shape(vaccine_rate)+
  tm_fill("2021-07-01", 
          n= 6,
          style = "jenks", 
          title = "Vaccine Rate") +
  tm_layout(main.title = "Distribution of COVID-19 Case Rate in July 2021",
            main.title.position = "center",
            main.title.size = 1,
            legend.height = 0.5, 
            legend.width = 0.4,
            frame = TRUE) +
  tm_borders(alpha = 0.5)

```

```{r}
# plot it for all 12 months 
jenks_plot <- function(df, varname) {
  tm_shape(vaccine_rate) +
    tm_polygons() +
  tm_shape(df) +
    tm_fill(varname, 
          n= 6,
          style = "jenks", 
          title = "Vaccine Rate") +
    tm_layout(main.title = varname,
          main.title.position = "center",
          main.title.size = 1.2,
          legend.height = 0.45, 
          legend.width = 0.35,
          frame = TRUE) +
    tm_borders(alpha = 0.5)
}

```

```{r}
# split it up into multiple arranges to make it easier to see
tmap_mode("plot")
tmap_arrange(jenks_plot(vaccine_rate, "2021-08-01"),
             jenks_plot(vaccine_rate, "2021-12-01"),
             jenks_plot(vaccine_rate, "2022-02-01"),
             jenks_plot(vaccine_rate, "2022-05-01"))
```

## 6.2 Analysis of the Spatial Patterns Revealed by the Choropleth Maps

blah blah blah
